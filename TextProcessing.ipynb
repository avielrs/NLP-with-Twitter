{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/avielstern/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import NLTK\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "spacy.prefer_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import june date with sentiment analysis\n",
    "df = pd.read_csv('data/2020-08_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup text data for matrix transformation with TFIDF\n",
    "1. Punctuation, lowercase\n",
    "2. Stop Words\n",
    "3. Lemmatization\n",
    "4. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "spc = spacy.load(\"en_core_web_sm\")\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "# import stopwords from spacy\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "\n",
    "#add words to stopword list\n",
    "all_stopwords |= {\"likes\",\"like\",\"ya\", \"-PRON-\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"—\"}\n",
    "\n",
    "print(string.punctuation)\n",
    "\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "def my_tokenizer(tweet):\n",
    "\n",
    "    for punctuation_mark in string.punctuation:\n",
    "        # Remove punctuation and set to lower case\n",
    "        tweet = tweet.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    tknzr = TweetTokenizer()\n",
    "    words = tknzr.tokenize(tweet)\n",
    "\n",
    "    lem_words = []\n",
    "\n",
    "    for i in words:\n",
    "        token = sp(i)\n",
    "        for word in token:\n",
    "            lem_words.append(word.lemma_)\n",
    "\n",
    "    tokens_filtered= [word for word in lem_words if not word in all_stopwords]\n",
    "    tweet = (\" \").join(tokens_filtered)\n",
    "\n",
    "    for punctuation_mark in string.punctuation:\n",
    "        tweet = tweet.replace(punctuation_mark,'')\n",
    "\n",
    "   \n",
    "    tweet = re.sub(r'^\\s+', '', tweet)  # remove spaces at the beginning\n",
    "    tweet = re.sub(r'\\s+$', '', tweet)  # remove spaces at the end\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)  # replace consecutive spaces\n",
    "    \n",
    "    # Retokenize again: \n",
    "    tknzr = TweetTokenizer()\n",
    "    tokenized_tweet = tknzr.tokenize(tweet)\n",
    "    \n",
    "    return tokenized_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TFIDF \n",
    "Convert a collection of raw documents to a matrix of TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117852"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_df must be at least 25% of the doc\n",
    "tfidf = TfidfVectorizer(min_df=0.25, tokenizer=my_tokenizer, ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117852, 41)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=0.05, tokenizer=my_tokenizer, ngram_range = (1,3))\n",
    "\n",
    "tfidf_vect = tfidf.fit_transform(X).todense()\n",
    "tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    min_df (float or int, default=1)\n",
    "\n",
    "    When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>18.285218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kamalaharris</td>\n",
       "      <td>16.712841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>joebiden</td>\n",
       "      <td>14.178305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>president</td>\n",
       "      <td>12.334887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>people</td>\n",
       "      <td>11.241789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>trump</td>\n",
       "      <td>7.891518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>america</td>\n",
       "      <td>6.146243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vote</td>\n",
       "      <td>5.946646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stand</td>\n",
       "      <td>3.913132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>life</td>\n",
       "      <td>3.738629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word      count\n",
       "19  realdonaldtrump  18.285218\n",
       "14     kamalaharris  16.712841\n",
       "13         joebiden  14.178305\n",
       "18        president  12.334887\n",
       "17           people  11.241789\n",
       "25            trump   7.891518\n",
       "0           america   6.146243\n",
       "26             vote   5.946646\n",
       "22            stand   3.913132\n",
       "15             life   3.738629"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = np.array(np.sum(tfidf_vect, axis=0)).reshape((-1,))\n",
    "words = np.array(tfidf.get_feature_names())\n",
    "words_df = pd.DataFrame({\"word\":words, \n",
    "                         \"count\":word_counts})\n",
    "words_df.sort_values(by=\"count\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>18.285218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kamalaharris</td>\n",
       "      <td>16.712841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>joebiden</td>\n",
       "      <td>14.178305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>president</td>\n",
       "      <td>12.334887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>people</td>\n",
       "      <td>11.241789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word      count\n",
       "19  realdonaldtrump  18.285218\n",
       "14     kamalaharris  16.712841\n",
       "13         joebiden  14.178305\n",
       "18        president  12.334887\n",
       "17           people  11.241789"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sort_values(by=\"count\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>america</th>\n",
       "      <th>america forever</th>\n",
       "      <th>america forever vote</th>\n",
       "      <th>defender</th>\n",
       "      <th>defender america</th>\n",
       "      <th>defender america forever</th>\n",
       "      <th>depend</th>\n",
       "      <th>folk</th>\n",
       "      <th>folk defender</th>\n",
       "      <th>folk defender america</th>\n",
       "      <th>...</th>\n",
       "      <th>realdonaldtrump</th>\n",
       "      <th>realdonaldtrump life</th>\n",
       "      <th>realdonaldtrump life depend</th>\n",
       "      <th>stand</th>\n",
       "      <th>stand folk</th>\n",
       "      <th>stand folk defender</th>\n",
       "      <th>trump</th>\n",
       "      <th>vote</th>\n",
       "      <th>vote realdonaldtrump</th>\n",
       "      <th>vote realdonaldtrump life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183557</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135917</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.199804</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187273</td>\n",
       "      <td>0.20964</td>\n",
       "      <td>0.20964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579385</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.473563</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350655</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.515479</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.738676</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     america  america forever  america forever vote  defender  \\\n",
       "0   0.183557          0.20964               0.20964   0.20964   \n",
       "1   0.000000          0.00000               0.00000   0.00000   \n",
       "2   0.000000          0.00000               0.00000   0.00000   \n",
       "3   0.000000          0.00000               0.00000   0.00000   \n",
       "4   0.000000          0.00000               0.00000   0.00000   \n",
       "..       ...              ...                   ...       ...   \n",
       "95  0.473563          0.00000               0.00000   0.00000   \n",
       "96  0.000000          0.00000               0.00000   0.00000   \n",
       "97  0.000000          0.00000               0.00000   0.00000   \n",
       "98  0.738676          0.00000               0.00000   0.00000   \n",
       "99  0.000000          0.00000               0.00000   0.00000   \n",
       "\n",
       "    defender america  defender america forever   depend     folk  \\\n",
       "0            0.20964                   0.20964  0.20964  0.20964   \n",
       "1            0.00000                   0.00000  0.00000  0.00000   \n",
       "2            0.00000                   0.00000  0.00000  0.00000   \n",
       "3            0.00000                   0.00000  0.00000  0.00000   \n",
       "4            0.00000                   0.00000  0.00000  0.00000   \n",
       "..               ...                       ...      ...      ...   \n",
       "95           0.00000                   0.00000  0.00000  0.00000   \n",
       "96           0.00000                   0.00000  0.00000  0.00000   \n",
       "97           0.00000                   0.00000  0.00000  0.00000   \n",
       "98           0.00000                   0.00000  0.00000  0.00000   \n",
       "99           0.00000                   0.00000  0.00000  0.00000   \n",
       "\n",
       "    folk defender  folk defender america  ...  realdonaldtrump  \\\n",
       "0         0.20964                0.20964  ...         0.135917   \n",
       "1         0.00000                0.00000  ...         0.000000   \n",
       "2         0.00000                0.00000  ...         0.579385   \n",
       "3         0.00000                0.00000  ...         0.000000   \n",
       "4         0.00000                0.00000  ...         0.000000   \n",
       "..            ...                    ...  ...              ...   \n",
       "95        0.00000                0.00000  ...         0.350655   \n",
       "96        0.00000                0.00000  ...         0.000000   \n",
       "97        0.00000                0.00000  ...         0.000000   \n",
       "98        0.00000                0.00000  ...         0.000000   \n",
       "99        0.00000                0.00000  ...         1.000000   \n",
       "\n",
       "    realdonaldtrump life  realdonaldtrump life depend     stand  stand folk  \\\n",
       "0                0.20964                      0.20964  0.199804     0.20964   \n",
       "1                0.00000                      0.00000  0.000000     0.00000   \n",
       "2                0.00000                      0.00000  0.000000     0.00000   \n",
       "3                0.00000                      0.00000  0.000000     0.00000   \n",
       "4                0.00000                      0.00000  0.000000     0.00000   \n",
       "..                   ...                          ...       ...         ...   \n",
       "95               0.00000                      0.00000  0.515479     0.00000   \n",
       "96               0.00000                      0.00000  0.000000     0.00000   \n",
       "97               0.00000                      0.00000  0.000000     0.00000   \n",
       "98               0.00000                      0.00000  0.000000     0.00000   \n",
       "99               0.00000                      0.00000  0.000000     0.00000   \n",
       "\n",
       "    stand folk defender  trump      vote  vote realdonaldtrump  \\\n",
       "0               0.20964    0.0  0.187273               0.20964   \n",
       "1               0.00000    0.0  0.000000               0.00000   \n",
       "2               0.00000    0.0  0.000000               0.00000   \n",
       "3               0.00000    0.0  0.000000               0.00000   \n",
       "4               0.00000    0.0  0.000000               0.00000   \n",
       "..                  ...    ...       ...                   ...   \n",
       "95              0.00000    0.0  0.000000               0.00000   \n",
       "96              0.00000    0.0  0.000000               0.00000   \n",
       "97              0.00000    0.0  0.000000               0.00000   \n",
       "98              0.00000    0.0  0.000000               0.00000   \n",
       "99              0.00000    0.0  0.000000               0.00000   \n",
       "\n",
       "    vote realdonaldtrump life  \n",
       "0                     0.20964  \n",
       "1                     0.00000  \n",
       "2                     0.00000  \n",
       "3                     0.00000  \n",
       "4                     0.00000  \n",
       "..                        ...  \n",
       "95                    0.00000  \n",
       "96                    0.00000  \n",
       "97                    0.00000  \n",
       "98                    0.00000  \n",
       "99                    0.00000  \n",
       "\n",
       "[100 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_vector = pd.DataFrame(columns=tfidf.get_feature_names(), data=tfidf_vect)\n",
    "display(df_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector.to_csv('vector_08_2020.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
